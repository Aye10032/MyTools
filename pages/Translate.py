import os

import httpx
import streamlit as st
import yaml
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from loguru import logger

from ui.Component import side_bar_links

st.set_page_config(
    page_title='å·¥å…·ç®±',
    page_icon='ðŸ”¨',
    layout='wide',
)

st.title("ä¸€é”®ç”Ÿæˆç¿»è¯‘æ€»ç»“")

with st.sidebar:
    side_bar_links()

    st.toggle('åŽ»é™¤æ¢è¡Œ', key='trans_reformat')
    st.toggle('æ€»ç»“', key='trans_conclusion')

    st.toggle('è¾“å‡ºæ ¼å¼', key='trans_text_mode')
    if st.session_state.get('trans_text_mode'):
        st.caption('markdown')
    else:
        st.caption('latex')


def get_translate_and_conclude(question: str, step: int):
    if step == 0:
        _prompt = ChatPromptTemplate.from_messages(
            [
                SystemMessage("You are an AI academic assistant and should answer user questions rigorously."),
                ("human",
                 "ä½ å°†æ”¶åˆ°ä¸€ä¸ªè®ºæ–‡çš„ç‰‡æ®µã€‚é¦–å…ˆï¼Œå°†è¿™æ®µæ–‡æœ¬ä»¥å­¦æœ¯é£Žæ ¼**ç¿»è¯‘ä¸ºä¸­æ–‡**ï¼Œä¸è¦æ¼å¥ã€‚å¯¹äºŽæ‰€æœ‰çš„ç‰¹æ®Šç¬¦å·å’Œlatexä»£ç ï¼Œè¯·ä¿æŒåŽŸæ ·ä¸è¦æ”¹å˜ã€‚"
                 "å¯¹äºŽæ–‡ä¸­ä¸€äº›æ˜¾å¾—ä¸Žä¸Šä¸‹æ–‡çªå…€çš„æ•°å­—ï¼Œå¾ˆå¤§å¯èƒ½æ˜¯å¼•ç”¨æ–‡çŒ®ï¼Œè¯·ä½¿ç”¨latexè¯­æ³•å°†å®ƒä»¬è¡¨ç¤ºä¸ºä¸€ä¸ªä¸Šæ ‡ï¼Œå¹¶ä½¿ç”¨ç¾Žå…ƒç¬¦å·åŒ…å›´ï¼Œå¦‚$^2$ã€‚è¿™æ˜¯ä½ è¦ç¿»è¯‘çš„æ–‡çŒ®ç‰‡æ®µ:\n{question}"),
            ]
        )
    elif step == 1:
        _prompt = ChatPromptTemplate.from_messages(
            [
                SystemMessage(content="You are an AI academic assistant and should answer user questions rigorously."),
                HumanMessage(
                    content=f"""é¦–å…ˆï¼Œå°†è¿™æ®µæ–‡æœ¬**ç¿»è¯‘ä¸ºä¸­æ–‡**ï¼Œä¸è¦æ¼å¥ã€‚å¯¹äºŽæ‰€æœ‰çš„ç‰¹æ®Šç¬¦å·å’Œlatexä»£ç ï¼Œè¯·ä¿æŒåŽŸæ ·ä¸è¦æ”¹å˜:
                    {st.session_state.translate_messages[-3]}"""
                ),
                AIMessage(content=str(st.session_state.translate_messages[-2])),
                HumanMessage(content=question),
            ]
        )
    else:
        raise Exception("Wrong step value")

    with open('/home/aye/Service/MyTools/config.yaml', 'r') as f:
        data = yaml.load(f.read(), yaml.FullLoader)
    http_client = httpx.Client(proxies='http://127.0.0.1:7890')
    llm = ChatOpenAI(
        model_name="gpt-3.5-turbo",
        http_client=http_client,
        temperature=0,
        openai_api_key=data['llm']['openai']['api_key'],
        streaming=True
    )

    chain = _prompt | llm

    if step == 0:
        llm_result = chain.stream({"question": question})
    else:
        llm_result = chain.stream({"question": question})

    return llm_result


col1, col2 = st.columns([1, 1], gap="medium")

if 'translate_messages' not in st.session_state:
    st.session_state.translate_messages = []

if 'markdown_text' not in st.session_state:
    st.session_state.markdown_text = ''

chat_container = col1.container(height=610, border=False)

with chat_container:
    for message in st.session_state.translate_messages:
        icon = 'logo.png' if message['role'] != 'user' else None
        with st.chat_message(message['role']):
            st.markdown(message['content'])

with col2:
    if st.session_state.markdown_text != '':
        with st.container(height=520, border=True):
            st.markdown(st.session_state.markdown_text)
        if st.session_state.get('trans_text_mode'):
            st.code(st.session_state.markdown_text, language='markdown')
        else:
            st.code(st.session_state.markdown_text, language='latex')

if prompt := st.chat_input():
    st.session_state.translate_messages = []
    if st.session_state.get('trans_reformat'):
        prompt = prompt.replace("\n", " ").replace("\r", "")

    logger.info(f'[translate]: {prompt}')
    prompt = prompt.replace('$', r'\$')

    chat_container.chat_message("human").write(prompt)
    st.session_state.translate_messages.append({'role': 'user', 'content': prompt})

    response = get_translate_and_conclude(prompt, 0)
    translate_result = chat_container.chat_message("ai").write_stream(response)
    st.session_state.translate_messages.append({'role': 'assistant', 'content': translate_result})

    if st.session_state.get('trans_conclusion'):
        query = "æŽ¥ä¸‹æ¥ï¼Œè¯·ç”¨ä¸¤åˆ°å››å¥è¯æ€»ç»“ä¸€ä¸‹è¿™æ®µæ–‡æœ¬çš„å†…å®¹"
        chat_container.chat_message("human").write(query)
        st.session_state.translate_messages.append({'role': 'user', 'content': query})

        response = get_translate_and_conclude(query, 1)
        conclusion_result = chat_container.chat_message("ai").write_stream(response)
        logger.info(f"(conclude): {conclusion_result}")
        st.session_state.translate_messages.append({'role': 'assistant', 'content': conclusion_result})

        if st.session_state.get('trans_text_mode'):
            markdown_text = f"""{prompt}\t\r\n{translate_result}\t\r\n> {conclusion_result}"""
        else:
            markdown_text = f"""{prompt}\n\n{translate_result}\n\n\\tbox{{ {conclusion_result} }}"""
            markdown_text = markdown_text.replace('%', r'\%')
        st.session_state.markdown_text = markdown_text
    else:
        markdown_text = f"""{prompt}\t\r\n{translate_result}"""
        st.session_state.markdown_text = markdown_text

    st.rerun()
